{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOR6syqQuD3mRhtzx31al3Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Melissahachemi/classificateur/blob/main/Mod%C3%A8le_G%C3%A9n%C3%A9ratif.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXIiXRJmDyND",
        "outputId": "c5efb0e3-5b65-4913-b881-d07207403967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-21 15:20:43--  https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 65862309 (63M) [text/plain]\n",
            "Saving to: ‘IMDb_Reviews.csv.1’\n",
            "\n",
            "IMDb_Reviews.csv.1  100%[===================>]  62.81M   199MB/s    in 0.3s    \n",
            "\n",
            "2025-02-21 15:20:43 (199 MB/s) - ‘IMDb_Reviews.csv.1’ saved [65862309/65862309]\n",
            "\n",
            "   y    P(y)\n",
            "0  0  0.4993\n",
            "1  1  0.5007\n",
            "La longueur du vocabulaire est : 27452\n",
            "Tableau des probabilités P(x/y=0) :\n",
            "             mot  P(x/y=0)\n",
            "0              i  0.000072\n",
            "1         wanted  0.000072\n",
            "2             to  0.000145\n",
            "3           love  0.000072\n",
            "4           this  0.000109\n",
            "...          ...       ...\n",
            "27325   cuthbert  0.000212\n",
            "27326  granger's  0.000073\n",
            "27327     fatima  0.000071\n",
            "27328     />8/10  0.000073\n",
            "27329      togar  0.000073\n",
            "\n",
            "[27330 rows x 2 columns]\n",
            "\n",
            "Tableau des probabilités P(x/y=1) :\n",
            "                mot  P(x/y=1)\n",
            "0              just  0.000072\n",
            "1               got  0.000073\n",
            "2            around  0.000072\n",
            "3                to  0.000323\n",
            "4            seeing  0.000073\n",
            "...             ...       ...\n",
            "27346      pitiful.  0.000073\n",
            "27347       'movie'  0.000072\n",
            "27348  thunderbirds  0.000073\n",
            "27349     tripe.<br  0.000072\n",
            "27350        blows.  0.000072\n",
            "\n",
            "[27351 rows x 2 columns]\n",
            "Vecteur sac de mots : [6 1 0 ... 0 0 0]\n",
            "Fréquences des mots dans le texte : {'bring': 1, 'a': 2, 'box': 1, 'of': 3, 'kleenex': 1, 'to': 3, 'this': 1, 'funny,': 1, 'engaging,': 1, 'and': 5, 'moving': 1, 'weeper.': 1, 'the': 10, 'two': 2, 'leading': 1, 'actors': 1, 'give': 1, 'tour': 1, 'de': 1, 'force': 1, 'performances': 1, '-': 2, 'there': 1, 'was': 1, 'considerable': 1, 'debate': 1, 'afterward': 1, 'about': 2, 'whether': 1, 'they': 1, 'are': 4, 'really': 1, 'disabled': 1, '(they': 1, 'not.)': 1, 'i': 1, 'appreciated': 1, 'that': 3, 'for': 2, 'once': 1, 'filmmakers': 1, 'dared': 1, 'be': 1, 'politically': 1, 'incorrect': 1, 'by': 1, 'depicting': 1, 'people': 1, 'with': 1, 'severe': 1, 'physical': 1, 'disabilities': 1, 'as': 2, 'fully': 1, 'developed': 1, 'people,': 1, 'character': 2, 'flaws': 1, 'all.': 1, 'result,': 1, 'their': 2, 'believability': 1, 'engages': 1, 'us': 2, 'makes': 1, 'grow': 1, 'like': 1, 'them': 1, 'care': 1, 'conflicts.': 1, 'story': 1, 'structure': 1, 'is': 2, 'formulaic,': 1, 'many': 1, 'secondary': 1, 'characters': 2, 'merely': 1, 'types,': 1, 'but': 1, 'central': 2, 'so': 1, 'riveting': 1, 'it': 1, \"doesn't\": 1, 'matter.': 1, '<br': 1, '/><br': 1, '/>interesting': 1, 'original': 1, 'title,': 1, 'inside': 1, \"i'm\": 1, 'dancing,': 1, 'reflects': 1, 'viewpoint': 1, 'michael,': 1, 'while': 1, 'new': 1, 'title': 1, 'usa': 1, 'release': 1, 'suggests': 1, 'rory': 1, 'figure.': 1}\n",
            "Score pour la classe 0 : -1227.0400478769343\n",
            "Score pour la classe 1 : -1198.7826785421887\n",
            "Texte du dev: Bring a box of Kleenex to this funny, engaging, and moving weeper. The two leading actors give tour de force performances - there was considerable debate afterward about whether they are really disabled (they are not.) I appreciated that for once the filmmakers dared to be politically incorrect by depicting people with severe physical disabilities as fully developed people, character flaws and all. As a result, their believability engages us and makes us grow to like them and care about their conflicts. The story structure is formulaic, and many of the secondary characters are merely types, but the two central characters are so riveting that it doesn't matter. <br /><br />Interesting - the original title, INSIDE I'M DANCING, reflects the viewpoint of the character Michael, while the new title for USA release suggests that Rory is the central figure.\n",
            "Classe prédite: 1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "#recupération des données\n",
        "\n",
        "!wget https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\n",
        "dataset = \"IMDb_Reviews.csv\"\n",
        "df = pd.read_csv(dataset)\n",
        "\n",
        "### Étape 1 : Mélanger le DataFrame\n",
        "\n",
        "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# - `sample(frac=1)` mélange le DataFrame en sélectionnant 100% des lignes au hasard.\n",
        "# - `random_state` assure que le mélange est reproductible.\n",
        "# - `reset_index(drop=True)` réinitialise l'index sans ajouter l'ancien index au DataFrame.\n",
        "\n",
        "### Étape 2 : Diviser le DataFrame\n",
        "\n",
        "# Calculer le point de division\n",
        "split_idx = int(len(df_shuffled) * 0.8)\n",
        "\n",
        "# Diviser en train et développement\n",
        "df_train = df_shuffled[:split_idx]\n",
        "df_dev = df_shuffled[split_idx:]\n",
        "\n",
        "### Étape 3 : Sauvegarder les DataFrames dans des Fichiers\n",
        "\n",
        "df_train.to_csv('imdb_train.csv', index=False)\n",
        "df_dev.to_csv('imdb_dev.csv', index=False)\n",
        "\n",
        "df_train_loaded = pd.read_csv(\"imdb_train.csv\")\n",
        "df_dev_loaded =  pd.read_csv(\"imdb_dev.csv\")\n",
        "\n",
        "## preparation du vocabulaire\n",
        "\n",
        "class Vocabulaire:\n",
        "    def __init__(self, token_unk='<unk>'):\n",
        "        self.freq_mots = {}  # Pour compter la fréquence des mots\n",
        "        self.mot_index = {token_unk: 0}  # Dictionnaire mot -> index, avec 'unk' comme premier mot\n",
        "        self.index_mot = {0: token_unk}  # Dictionnaire index -> mot, avec 'unk' comme premier mot\n",
        "        self.longueur = 1  # Nombre de mots uniques dans le vocabulaire, en commençant par 'unk'\n",
        "        self.token_unk = token_unk\n",
        "\n",
        "    def ajouter_texte(self, texte):\n",
        "        for mot in texte.split():\n",
        "            mot = mot.lower()  # Convertit le mot en minuscule\n",
        "            if mot in self.freq_mots:\n",
        "                self.freq_mots[mot] += 1\n",
        "            else:\n",
        "                self.freq_mots[mot] = 1\n",
        "\n",
        "    def construire_vocabulaire(self, min_occurrence=15):\n",
        "        # Commencez à 1 car 0 est réservé pour 'unk'\n",
        "        index = 1\n",
        "        for mot, freq in self.freq_mots.items():\n",
        "            if freq >= min_occurrence and mot not in self.mot_index:\n",
        "                self.mot_index[mot] = index\n",
        "                self.index_mot[index] = mot\n",
        "                index += 1\n",
        "        # Mise à jour de la longueur après la construction\n",
        "        self.longueur = len(self.mot_index)\n",
        "\n",
        "    def transformer_texte_en_indices(self, texte):\n",
        "        return [self.mot_index.get(mot.lower(), self.mot_index[self.token_unk]) for mot in texte.split()]\n",
        "\n",
        "    def transformer_texte_en_vecteur(self, texte):\n",
        "        \"\"\" Transformer le texte en vecteur de fréquences des mots du vocabulaire. \"\"\"\n",
        "        vecteur = np.zeros(self.longueur, dtype=int)\n",
        "        for mot in texte.split():\n",
        "            mot = mot.lower()\n",
        "            index = self.mot_index.get(mot, self.mot_index[self.token_unk])\n",
        "            vecteur[index] += 1\n",
        "        return vecteur\n",
        "\n",
        "    def construire_depuis_dataframe(self, df, colonne):\n",
        "        \"\"\" Parcourt le DataFrame et ajoute tous les mots de la colonne spécifiée au vocabulaire. \"\"\"\n",
        "        df[colonne].str.lower().apply(self.ajouter_texte)\n",
        "        self.construire_vocabulaire()\n",
        "#calcule du nombre d'occurences de 0 et de 1  dans le train\n",
        "nb_0=df_train_loaded['sentiment'].value_counts().get(0, 0)\n",
        "nb_1=df_train_loaded['sentiment'].value_counts().get(1, 0)\n",
        "\n",
        "#calcule de la taille de train\n",
        "taille_train=len(df_train_loaded)\n",
        "\n",
        "#calcule des proba\n",
        "p_y_0= nb_0 / taille_train\n",
        "p_y_1=nb_1 / taille_train\n",
        "\n",
        "#creation du tableau des proba\n",
        "tableau_probabilites = pd.DataFrame({\n",
        "    'y': [0, 1],\n",
        "    'P(y)': [p_y_0, p_y_1]\n",
        "})\n",
        "\n",
        "print(tableau_probabilites)\n",
        "\n",
        "\n",
        "vocab=Vocabulaire()\n",
        "vocab.construire_depuis_dataframe(df_train, 'review')\n",
        "\n",
        "longueur_vocabulaire = vocab.longueur\n",
        "print(f\"La longueur du vocabulaire est : {longueur_vocabulaire}\")\n",
        "\n",
        "def calculer_probabilites_conditionnelles(df, vocab):\n",
        "    \"\"\"Calcule P(x/y) pour chaque mot x et chaque classe y.\"\"\"\n",
        "\n",
        "    # Initialisation des dictionnaires pour stocker les résultats\n",
        "    probabilites_x_y_0 = {}\n",
        "    probabilites_x_y_1 = {}\n",
        "\n",
        "    # Taille du vocabulaire (pour le lissage de Laplace)\n",
        "    taille_vocabulaire = vocab.longueur\n",
        "\n",
        "    # Parcourir les données d'entraînement\n",
        "    for index, row in df.iterrows():\n",
        "        texte = row['review']\n",
        "        y = row['sentiment']\n",
        "\n",
        "        # Compter les occurrences de mots dans le texte pour chaque classe\n",
        "        mots = texte.split()\n",
        "        comptes_mots = {}\n",
        "        for mot in mots:\n",
        "            mot = mot.lower()  # Convertir en minuscules pour uniformité\n",
        "            if mot in vocab.mot_index:  # Ignorer les mots inconnus\n",
        "                if mot not in comptes_mots:\n",
        "                    comptes_mots[mot] = 0\n",
        "                comptes_mots[mot] += 1\n",
        "\n",
        "        # Calculer les probabilités conditionnelles pour chaque mot\n",
        "        for mot, count in comptes_mots.items():\n",
        "            if y == 0:\n",
        "                probabilites_x_y_0[mot] = (count + 1) / (sum(comptes_mots.values()) + taille_vocabulaire)\n",
        "            else:\n",
        "                probabilites_x_y_1[mot] = (count + 1) / (sum(comptes_mots.values()) + taille_vocabulaire)\n",
        "\n",
        "    return probabilites_x_y_0, probabilites_x_y_1\n",
        "\n",
        "# Calculer les probabilités conditionnelles\n",
        "probabilites_x_y_0, probabilites_x_y_1 = calculer_probabilites_conditionnelles(df_train_loaded, vocab)\n",
        "\n",
        "# Créer des DataFrames pour afficher les résultats\n",
        "tableau_probabilites_x_y_0 = pd.DataFrame(list(probabilites_x_y_0.items()), columns=['mot', 'P(x/y=0)'])\n",
        "tableau_probabilites_x_y_1 = pd.DataFrame(list(probabilites_x_y_1.items()), columns=['mot', 'P(x/y=1)'])\n",
        "\n",
        "print(\"Tableau des probabilités P(x/y=0) :\")\n",
        "print(tableau_probabilites_x_y_0)\n",
        "\n",
        "print(\"\\nTableau des probabilités P(x/y=1) :\")\n",
        "print(tableau_probabilites_x_y_1)\n",
        "\n",
        "\n",
        "## sac de mots\n",
        "def creer_vecteur_sac_de_mots(vocab):\n",
        "    \"\"\"Crée un vecteur sac de mots initialisé avec des 0, avec la taille du vocabulaire.\"\"\"\n",
        "    vecteur = np.zeros(vocab.longueur, dtype=int)\n",
        "    return vecteur\n",
        "\n",
        "def remplir_vecteur_sac_de_mots(texte, vocab, vecteur):\n",
        "    \"\"\"Rempli le vecteur sac de mots avec les fréquences des mots du texte.\"\"\"\n",
        "    frequences_mots = {}  # Dictionnaire pour stocker les fréquences des mots dans le t\n",
        "    for mot in texte.split():\n",
        "        mot = mot.lower()\n",
        "        index = vocab.mot_index.get(mot, 0)  # 0 pour le token <unk>\n",
        "        vecteur[index] += 1\n",
        "        if mot not in frequences_mots:\n",
        "            frequences_mots[mot] = 0\n",
        "        frequences_mots[mot] += 1\n",
        "    return frequences_mots\n",
        "\n",
        "\n",
        "# gerer l'underflow\n",
        "\n",
        "def calculer_score(vecteur, probabilites_x_y, vocab):\n",
        "    \"\"\"Calcule le score pour une classe donnée.\"\"\"\n",
        "    score = 0\n",
        "    for i, freq in enumerate(vecteur):\n",
        "        if freq > 0:\n",
        "            mot = vocab.index_mot.get(i)\n",
        "            if mot in probabilites_x_y:\n",
        "                proba = probabilites_x_y[mot]\n",
        "                score += freq * math.log(proba)  # Utilisation du logarithme pour éviter les petits nombres\n",
        "    return score\n",
        "\n",
        "def predire_classe(texte, vocab, probabilites_x_y_0, probabilites_x_y_1):\n",
        "    \"\"\"Prédit la classe (0 ou 1) pour un texte donné.\"\"\"\n",
        "    vecteur = creer_vecteur_sac_de_mots(vocab)\n",
        "    frequences_mots = remplir_vecteur_sac_de_mots(texte, vocab, vecteur)\n",
        "\n",
        "\n",
        "    score_0 = calculer_score(vecteur, probabilites_x_y_0, vocab)\n",
        "    score_1 = calculer_score(vecteur, probabilites_x_y_1, vocab)\n",
        "\n",
        "    print(\"Vecteur sac de mots :\", vecteur)\n",
        "    print(\"Fréquences des mots dans le texte :\", frequences_mots)\n",
        "    print(\"Score pour la classe 0 :\", score_0)\n",
        "    print(\"Score pour la classe 1 :\", score_1)\n",
        "\n",
        "    if score_0 > score_1:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "\n",
        "texte_dev = df_dev_loaded['review'].iloc[1]  # Prendre le premier texte du dev\n",
        "classe_predite = predire_classe(texte_dev, vocab, probabilites_x_y_0, probabilites_x_y_1)\n",
        "\n",
        "print(f\"Texte du dev: {texte_dev}\")\n",
        "print(f\"Classe prédite: {classe_predite}\")"
      ]
    }
  ]
}